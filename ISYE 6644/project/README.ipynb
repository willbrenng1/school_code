{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Game of Life: Analyzing the Impact of Initial Conditions on Game Duration \n",
    "- This project simulates John Conway's Game of Life through different matrix sizes and initial percent of alive cells\n",
    "- The primary goal of this project is to understand how these different starting conditions impact the behavior of the simulation, including the duration of the simulation and end state of the game.\n",
    "- By comparing different groupings, the objective is to determine the statistical significance between the starting conditions and how they influence the outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project File Contents\n",
    "-  Module Folders\n",
    "    - There are three module folders in the project file; analysis, simulation and visulization. Each contain the following functions\n",
    "      - analysis\n",
    "        - cohens_f(f_stat, df_groups, df_obs) \n",
    "          - Calculates Cohen's f, a measure of effect size for ANOVA. Takes the F-statistic and degrees of freedom for groups and observations to compute the proportion of variance explained and return the corresponding effect size. \n",
    "    \n",
    "        - anova_analysis(df) \n",
    "          - Performs one-way ANOVA for each unique matrix size in the dataset to test if the mean number of generations differs significantly between initial percent alive groups. Also calculates Cohen’s f for each matrix size and returns a summary DataFrame containing the F-statistic, p-value, and Cohen’s f. \n",
    "\n",
    "        - calc_matrix_size_and_initial_percent_alive_group_stats(df) \n",
    "          - Computes descriptive statistics including mean, standard deviation, standard error, and 95% confidence interval for the number of generations per matrix size and initial percent alive group based on simulation results. Returns a sorted DataFrame by confidence interval width. \n",
    "\n",
    "        - determine_sample_size(df) \n",
    "          - Uses the Cohen's f values from ANOVA results to calculate the minimum sample size required for each matrix size group to detect an effect with 90% power at a 5% significance level using F-test power analysis. Returns a dictionary mapping matrix size to required sample size. \n",
    "    \n",
    "        - required_n_per_group(grouped_stats, min_sample_size ,half_width=10, confidence=0.95)\n",
    "          - Estimates the sample size required for each group to achieve a confidence interval width no larger than a specified value (default: ±10), given the group's standard deviation and desired confidence level. Returns a dictionary with keys of matrix size and initial percent alive with required sample sizes. \n",
    "          - Selects the appropriate critical value based on the current sample size: \n",
    "            - If n >= 30, the z-statistic is used. \n",
    "            - If n < 30, the t-statistic with appropriate degrees of freedom is used. \n",
    "        - sample_v_final_stat_comparison(sample, final) \n",
    "          - Compares group statistics between sample and final simulation results. Calculates and returns deltas for means, standard deviations, standard errors, and confidence interval widths to observe and evaluate the impact of using optimized sample sizes. \n",
    "      - simulation\n",
    "        - generate_rand_matrix(rows, cols, p_ones) \n",
    "          - Creates a binary matrix of size (rows × cols) where a proportion p_ones of cells are alive (1) and the rest are dead (0), randomly distributed. Used to simulate initial conditions. \n",
    "        - get_neighbors(mat) \n",
    "          - Builds a dictionary mapping each cell’s coordinates to a list of values of neighbors \n",
    "        - next_gen(mat) \n",
    "          - Generates the next state of the matrix using Conway’s Game of Life rules. Applies birth, survival, and death logic based on sum of neighbor to return the new matrix. \n",
    "        - matrix_data_collection(mat, gen_num, run_num, collection_dict, alive_percent, matrix_size) \n",
    "          - Records the number of alive cells and simulation description data at a given generation. Updates a shared dictionary with values for later aggregation and analysis. \n",
    "        - run_game(mat, run_num, matrix_size, master_data_collection_dict, alive_percent, max_steps=1000) \n",
    "          - Simulates Conway’s Game of Life from a given matrix until reaching a steady state, all cells are dead, or the maximum number of steps is reached. Logs generation-level and run-level data into a shared dictionary. \n",
    "        - sample_runs(number_of_sample_per_matrix_size_and_percent_alive, max_steps) \n",
    "          - Executes a fixed number of simulations for every combination of matrix size (10×10 to 100×100) and initial alive percentage (5% to 95%). Returns a DataFrame with merged generation and run data across all trials. \n",
    "        - final_run(dicts, max_steps) \n",
    "          - Runs simulations using optimized sample sizes per condition (matrix size and initial percentage alive), as determined from prior analysis. Returns a DataFrame of merged results for final evaluation.\n",
    "\n",
    "      - visulization\n",
    "        - show_end_state_circle_chart(df) \n",
    "          - Creates a donut-style pie chart showing the distribution of how simulations terminated: \n",
    "            - dead– all cells died out\n",
    "            - steady\"– reached a steady state\n",
    "            - max – hit the maximum number of allowed generation \n",
    "        - show_random_sample_runs(df) \n",
    "          - Selects 6 random simulation runs with more than one generation and plots line charts of alive cell counts over generations. Subplots are labeled with matrix size, initial alive percentage, and termination reason. \n",
    "        - show_heat_map(df)\n",
    "          - Generates a heatmap showing the average number of generations until termination for each combination of matrix size and initial percent alive groups \n",
    "            - matrix size (y-axis) \n",
    "            - Initial alive cell percentage (x-axis) \n",
    "        - show_initial_percent_alive_ci_avg(df) \n",
    "          - Calculates and plots the average 95% confidence interval width for each matrix size and initial percent alive group. Gives a sense of variability and across trials per group. \n",
    "        - show_ci_delta(df, top_bottom, n) \n",
    "          - Plots a bar chart of the top or bottom n matrix size and initial alive percentage group based on largest position of negative change in confidence interval width between sample and final simulation\n",
    "        - difference_in_average_ci_percent_alive_groups(df,df2) \n",
    "          - Compares the difference between average confidence interval width of the sample outputs (df) to the average confidence interval width of the final outputs (df2) \n",
    "          - Plots a bar chart for ease of comparison as well as a table of results\n",
    "\n",
    "- simulation_run_notebook\n",
    "  - A Jupyter Notebook that walks through the full workflow of the project:\n",
    "    - Generates the initial set of simulation runs using sample_runs()\n",
    "    - Analyzes results and determines optimal sample sizes per group using \n",
    "    - calc_matrix_size_and_initial_percent_alive_group_stats() and required_n_per_group()\n",
    "    - Executes the final simulations with final_run()\n",
    "    - Optionally visualizes and compares initial and final simulation results using functions from the visualization module\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to Execute the Program\n",
    "1. Download the Project\n",
    "    - Ensure the simulation, analysis and visualization modules are downloaded into your directory\n",
    "2. Create a new virtual environment using either venv or conda\n",
    "  - Ensure python 3.13.1 is used in your environment\n",
    "3. Install all required python packages using the requirements.txt file\n",
    "  - `pip install -r requirements.txt`\n",
    "4. Import the following essential functions from their respective modules into either a Jypter Notebook or Python file\n",
    "  - `from simulation import generate_rand_matrix,get_neighbors,next_gen,matrix_data_collection,run_game,sample_runs, final_run`\n",
    "  - `from analysis import calc_matrix_size_and_initial_percent_alive_group_stats,required_n_per_group`\n",
    "5. Running the Simulation\n",
    "    - Initial Sampling: \n",
    "      - Call sample_runs() with your desired number of samples per group and the maximum number of generations for each run. \n",
    "      - `sample_data = sample_runs(samples_per_group=10, max_generations=100) `\n",
    "    - Calculate Group Statistics: \n",
    "      - Pass the simulation results to calc_matrix_size_and_initial_percent_alive_group_stats() to compute group mean, standard deviation, variance, and 95% confidence intervals. \n",
    "      - `stats = calc_matrix_size_and_initial_percent_alive_group_stats(sample_data)` \n",
    "    - Determine Sample Sizes: \n",
    "      - Feed the statistics into required_n_per_group() to calculate how many runs are needed to tighten the confidence intervals to an acceptable width. \n",
    "        - `required_sample_sizes = required_n_per_group(stats) `\n",
    "    - Final Simulation: \n",
    "      - Run final_run() with the optimized sample sizes to generate final output. \n",
    "        - `final_run(required_sample_sizes) `\n",
    "4. Optional: Visualizations and Analysis\n",
    "    - You can use any of the available visualization and analysis functions by passing in the outputs from either the sample or final simulation. While these are not essential to running the simulation, they are useful for exploring and presenting the results. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
